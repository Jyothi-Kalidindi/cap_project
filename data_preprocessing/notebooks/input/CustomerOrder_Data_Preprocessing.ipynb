{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8883b77",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reading the data into python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06421ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supressing the warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90f469a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "customerorders_df = pd.read_csv(open(source_data))\n",
    "customerorders_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eebe0e-48aa-4fe6-94f5-8b97adcea9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerorders_df.drop(['Customer ID','Times Reordered by Same Customer'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc68aa-4bae-43ca-ac92-2a3f50df2e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerorders_df.rename(columns = {'Product ID in Orders':'productid','Ordered by Customer ID':'userid','Order ID':'orderid','Product ID in Orders':'productid','Weight':'subproductid'}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d338e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape before deleting duplicate values:', customerorders_df.shape)\n",
    "\n",
    "# Removing duplicate rows if any\n",
    "customerorders_df = customerorders_df.drop_duplicates(['Brand Name','Product Name','subproductid'])\n",
    "print('Shape After deleting duplicate values:', customerorders_df.shape)\n",
    "\n",
    "# Printing sample data\n",
    "customerorders_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca833a-0fda-45a8-9703-a54e3202efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerorders_df.drop(['Brand Name','Product Name'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f46529",
   "metadata": {},
   "source": [
    "# Defining the problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a8ddd9",
   "metadata": {},
   "source": [
    "#### Create a predictive model which gives relevant products recommendations\n",
    "\n",
    "Predictors: Category, Sub Category, Brand Name, Product Rating, Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07433c8",
   "metadata": {},
   "source": [
    "# Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the sample rows in the data\n",
    "customerorders_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5ee969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Observing the summarized information of data\n",
    "# Data types, Missing values based on number of non-null values Vs total rows etc.\n",
    "# Remove those variables from data which have too many missing values (Missing Values > 30%)\n",
    "# Remove Qualitative variables which cannot be used in Machine Learning\n",
    "customerorders_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e16d49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the descriptive statistics of the data\n",
    "customerorders_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0b1d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding unique values for each column\n",
    "# TO understand which column is categorical and which one is Continuous\n",
    "# Typically if the numer of unique values are < 20 then the variable is likely to be a category otherwise continuous\n",
    "customerorders_df.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b919fa4",
   "metadata": {},
   "source": [
    "# Basic Data Exploration Results\n",
    "\n",
    "Based on the basic exploration above, we can create a simple report of the data, noting down the observations regaring each column. Hence, creating a initial roadmap for further analysis.\n",
    "\n",
    "The selected columns in this step are not final, further study will be done and then a final list will be created.\n",
    "\n",
    "- Category     : Selected. Categorical.\n",
    "- Sub Category : Selected. Categorical.\n",
    "- Brand Name   : Selected. Categorical.\n",
    "- Product Name: Selected. Categorical.\n",
    "- Name         : Selected. Categorical.\n",
    "- Weight       : Selected. Continuous.\n",
    "- MRP/Unit     : Selected. Continuous.\n",
    "- Qnty         : Selected. Continuous.\n",
    "- Unit Qnty    : Selected. Continuous.\n",
    "- Cost Price   : Selected. Continuous.\n",
    "- Product ID   : Selected. Continuous.\n",
    "- Product rating : Selected. Continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8059b49",
   "metadata": {},
   "source": [
    "# Visual Exploratory Data Analysis\n",
    "\n",
    "Categorical variables: Bar plot\n",
    "\n",
    "Continuous variables: Histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9133d697",
   "metadata": {},
   "source": [
    "## Visualize distribution of all the Categorical Predictor variables in the data using bar plots\n",
    "We can spot a categorical variable in the data by looking at the unique values in them. Typically a categorical variable contains less than 20 Unique values AND there is repetition of values, which means the data can be grouped by those unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85972f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting multiple bar charts at once for categorical variables\n",
    "# Since there is no default function which can plot bar charts for multiple columns at once\n",
    "# we are defining our own function for the same\n",
    "\n",
    "def PlotBarCharts(inpData, colsToPlot):\n",
    "    %matplotlib inline\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Generating multiple subplots\n",
    "    fig, subPlot=plt.subplots(nrows=1, ncols=len(colsToPlot), figsize=(50,5))\n",
    "    fig.suptitle('Bar charts of: '+ str(colsToPlot))\n",
    "\n",
    "    for colName, plotNumber in zip(colsToPlot, range(len(colsToPlot))):\n",
    "        inpData.groupby(colName).size().plot(kind='bar',ax=subPlot[plotNumber])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e1af62",
   "metadata": {},
   "source": [
    "# Bar Charts Interpretation\n",
    "These bar charts represent the frequencies of each category in the Y-axis and the category names in the X-axis.\n",
    "\n",
    "In this data, all the categorical columns except \"Brand Name\", \"Name\" and \"Product Name\" have satisfactory distribution for machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04849368",
   "metadata": {},
   "source": [
    "# Visualize distribution of all the Continuous Predictor variables in the data using histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ebb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerorders_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566993d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting histograms of multiple columns together\n",
    "\n",
    "customerorders_df.hist(['productid'], figsize=(10,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c5a3c",
   "metadata": {},
   "source": [
    "# Histogram Interpretation\n",
    "Histograms shows us the data distribution for a single continuous variable.\n",
    "\n",
    "The ideal outcome for histogram is a bell curve or slightly skewed bell curve. If there is too much skewness, then outlier treatment should be done and the column should be re-examined, if that also does not solve the problem then only reject the column.\n",
    "\n",
    "Selected Continuous Variables:\n",
    "\n",
    "- MRP/Unit   : Selected. Slightly skewed distribution, acceptable.\n",
    "- Qnty       : Selected. Slightly skewed distribution, acceptable.\n",
    "- Unit Qnty  : Selected. Skewed distribution, not acceptable.\n",
    "- Cost Price : Selected. Slightly skewed distribution, acceptable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce2e01b-b0c4-4fd2-9311-4e28adff5515",
   "metadata": {},
   "source": [
    "# Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b81f36eb-9212-4f84-9696-6afbad0b6b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "import json\n",
    "import os\n",
    "notebook_path = os.getcwd()\n",
    "con_path = os.path.join(notebook_path, \"connection.json\")\n",
    "with open(con_path, \"r\") as read_file:\n",
    "    con_j = json.load(read_file)\n",
    "    username=con_j['username']\n",
    "    password=con_j['password']\n",
    "    database=con_j['database']\n",
    "    server=con_j['server']\n",
    "    port=con_j['port']\n",
    "    engine = sqlalchemy.create_engine(\"mysql+pymysql://\"+username+\":\"+password+\"@\"+server+\":\"+port+\"/\"+database)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74f7766",
   "metadata": {},
   "source": [
    "# Outlier treatment\n",
    "Outliers are extreme values in the data which are far away from most of the values. You can see them as the tails in the histogram.\n",
    "\n",
    "Outlier must be treated one column at a time. As the treatment will be slightly different for each column.\n",
    "\n",
    "Why I should treat the outliers?\n",
    "\n",
    "Outliers bias the training of machine learning models. As the algorithm tries to fit the extreme value, it goes away from majority of the data.\n",
    "\n",
    "There are below two options to treat outliers in the data.\n",
    "\n",
    "- Option-1: Delete the outlier Records. Only if there are just few rows lost.\n",
    "- Option-2: Impute the outlier values with a logical business value\n",
    "\n",
    "In this data all the continuous variables have slightly skewed distribution, which is acceptable, hence no outlier treatment is required.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20333f3b",
   "metadata": {},
   "source": [
    "1. Length of productid >12\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of productid > 12\n",
    "customerorders_df[customerorders_df['productid'].astype(str).str.len() > 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac17d249-1070-400e-9b7b-31310c70be4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_records_df = customerorders_df[customerorders_df['productid'].astype(str).str.len() > 12]\n",
    "error_records_df.to_csv(unprocessed_data, mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a75d447",
   "metadata": {},
   "source": [
    "# Missing values treatment\n",
    "Missing values are treated for each column separately.\n",
    "\n",
    "If a column has more than 30% data missing, then missing value treatment cannot be done. That column must be rejected because too much information is missing.\n",
    "\n",
    "There are below options for treating missing values in data.\n",
    "\n",
    "- Delete the missing value rows if there are only few records\n",
    "- Impute the missing values with MEDIAN value for continuous variables\n",
    "- Impute the missing values with MODE value for categorical variables\n",
    "- Interpolate the values based on nearby values\n",
    "- Interpolate the values based on business logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291ecafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding how many missing values are there for each column\n",
    "customerorders_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbf1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_records_df = customerorders_df[customerorders_df.isnull().any(axis=1)]\n",
    "error_records_df.to_csv(unprocessed_data, mode='a', index=False, header=False)\n",
    "# error_records_df.to_sql('unprocesseddata', con=engine, if_exists='append', index=False)\n",
    "error_records_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff89245",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerorders_df.replace('', np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275f3122",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerorders_df.dropna(inplace=True)\n",
    "\n",
    "# Finding how many missing values are there for each column\n",
    "customerorders_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae17ea3b",
   "metadata": {},
   "source": [
    "All the missing values are removed now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447c2dea",
   "metadata": {},
   "source": [
    "# Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27be3585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the leading and trailing spaces of columns\n",
    "customerorders_df.columns = customerorders_df.columns.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d627f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerorders_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b95439-ed0a-428d-9b96-c281c6b9722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory_df.to_sql('PreprocessedData', con=engine, if_exists='append', index=False)\n",
    "import datetime\n",
    "  \n",
    "# using now() to get current time\n",
    "current_time = datetime.datetime.now()\n",
    "\n",
    "customerorders_df['totalprice']=0\n",
    "customerorders_df['orderdate']=current_time\n",
    "customerorders_df['quantity']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbfd4f4",
   "metadata": {},
   "source": [
    "# Save the file into local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a7deef",
   "metadata": {},
   "outputs": [],
   "source": [
    "customerorders_df.to_csv(preprocessed_data, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c41b58a-71cb-4ab4-8dd1-b8727aba9b88",
   "metadata": {},
   "source": [
    "# Save the data into local database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351fcee-7440-4116-ab56-ad3fc3b9b74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inventory_df.to_sql('PreprocessedData', con=engine, if_exists='append', index=False)\n",
    "order_df = customerorders_df[['orderid','orderdate','totalprice','userid']]\n",
    "order_df = order_df.drop_duplicates()\n",
    "order_df.to_sql('customerorders', con=engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec9b9b7-10c7-4cd8-b304-6018cf8efb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_details_df = customerorders_df[['orderid','productid','quantity','subproductid']]\n",
    "ordered_details_df = ordered_details_df.drop_duplicates()\n",
    "ordered_details_df.to_sql('customerorderdetails', con=engine, if_exists='replace', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
